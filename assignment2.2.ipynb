{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "q2_initialization.py code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def xavier_weight_init():\n",
    "  \"\"\"\n",
    "  Returns function that creates random tensor. \n",
    "\n",
    "  The specified function will take in a shape (tuple or 1-d array) and must\n",
    "  return a random tensor of the specified shape and must be drawn from the\n",
    "  Xavier initialization distribution.\n",
    "\n",
    "  Hint: You might find tf.random_uniform useful.\n",
    "  \"\"\"\n",
    "  def _xavier_initializer(shape, **kwargs):\n",
    "    \"\"\"Defines an initializer for the Xavier distribution.\n",
    "\n",
    "    This function will be used as a variable scope initializer.\n",
    "\n",
    "    https://www.tensorflow.org/versions/r0.7/how_tos/variable_scope/index.html#initializers-in-variable-scope\n",
    "\n",
    "    Args:\n",
    "      shape: Tuple or 1-d array that species dimensions of requested tensor.\n",
    "    Returns:\n",
    "      out: tf.Tensor of specified shape sampled from Xavier distribution.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "\n",
    "    \n",
    "    e=np.sqrt(6/np.sum(shape))\n",
    "    #print(np.sum(shape))\n",
    "    #print(e)\n",
    "    out=tf.random_uniform(shape=shape,minval=-e,maxval=e)\n",
    "    #assert out.get_shape() == shape\n",
    "    ### END YOUR CODE\n",
    "    return out\n",
    "  # Returns defined initializer function.\n",
    "  return _xavier_initializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "q2_initialization.py test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running basic tests...\n",
      "Basic (non-exhaustive) Xavier initialization tests pass\n",
      "\n"
     ]
    }
   ],
   "source": [
    "  print(\"Running basic tests...\")\n",
    "  xavier_initializer = xavier_weight_init()\n",
    "  shape = (1,)\n",
    "  xavier_mat = xavier_initializer(shape)\n",
    "  #print(xavier_mat.get_shape())\n",
    "  assert xavier_mat.get_shape() == shape\n",
    "\n",
    "  shape = [1, 2, 4]\n",
    "  xavier_mat = xavier_initializer(shape)\n",
    "  assert xavier_mat.get_shape() == shape\n",
    "  print(\"Basic (non-exhaustive) Xavier initialization tests pass\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    ".\n",
    "\n",
    "q2_NER code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Blas SGEMM launch failed : a.shape=(64, 150), b.shape=(150, 100), m=64, n=100, k=150\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Reshape/_21, HiddenLayer/Variable/read)]]\n\t [[Node: Adam/update_SoftmaxLayer/Variable_1/ApplyAdam/_56 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_325_Adam/update_SoftmaxLayer/Variable_1/ApplyAdam\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'MatMul', defined at:\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-b7f813de830d>\", line 409, in <module>\n    test_NER()\n  File \"<ipython-input-3-b7f813de830d>\", line 368, in test_NER\n    model = NERModel(config)\n  File \"<ipython-input-3-b7f813de830d>\", line 263, in __init__\n    y = self.add_model(window)\n  File \"<ipython-input-3-b7f813de830d>\", line 203, in add_model\n    h=tf.tanh(tf.matmul(window, self.weights, transpose_b=False) + biases1)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1729, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 1442, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(64, 150), b.shape=(150, 100), m=64, n=100, k=150\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Reshape/_21, HiddenLayer/Variable/read)]]\n\t [[Node: Adam/update_SoftmaxLayer/Variable_1/ApplyAdam/_56 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_325_Adam/update_SoftmaxLayer/Variable_1/ApplyAdam\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32mC:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    468\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    470\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas SGEMM launch failed : a.shape=(64, 150), b.shape=(150, 100), m=64, n=100, k=150\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Reshape/_21, HiddenLayer/Variable/read)]]\n\t [[Node: Adam/update_SoftmaxLayer/Variable_1/ApplyAdam/_56 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_325_Adam/update_SoftmaxLayer/Variable_1/ApplyAdam\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b7f813de830d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m   \u001b[0mtest_NER\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-b7f813de830d>\u001b[0m in \u001b[0;36mtest_NER\u001b[0;34m()\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[1;31m###\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         train_loss, train_acc = model.run_epoch(session, model.X_train,\n\u001b[0;32m--> 382\u001b[0;31m                                                 model.y_train)\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_dev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training loss: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-b7f813de830d>\u001b[0m in \u001b[0;36mrun_epoch\u001b[0;34m(self, session, input_data, input_labels, shuffle, verbose)\u001b[0m\n\u001b[1;32m    289\u001b[0m       loss, total_correct, _ = session.run(\n\u001b[1;32m    290\u001b[0m           \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorrect_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m           feed_dict=feed)\n\u001b[0m\u001b[1;32m    292\u001b[0m       \u001b[0mtotal_processed_examples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m       \u001b[0mtotal_correct_examples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtotal_correct\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32mC:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: Blas SGEMM launch failed : a.shape=(64, 150), b.shape=(150, 100), m=64, n=100, k=150\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Reshape/_21, HiddenLayer/Variable/read)]]\n\t [[Node: Adam/update_SoftmaxLayer/Variable_1/ApplyAdam/_56 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_325_Adam/update_SoftmaxLayer/Variable_1/ApplyAdam\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nCaused by op 'MatMul', defined at:\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 474, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tornado\\stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 501, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-b7f813de830d>\", line 409, in <module>\n    test_NER()\n  File \"<ipython-input-3-b7f813de830d>\", line 368, in test_NER\n    model = NERModel(config)\n  File \"<ipython-input-3-b7f813de830d>\", line 263, in __init__\n    y = self.add_model(window)\n  File \"<ipython-input-3-b7f813de830d>\", line 203, in add_model\n    h=tf.tanh(tf.matmul(window, self.weights, transpose_b=False) + biases1)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\", line 1729, in matmul\n    a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\", line 1442, in _mat_mul\n    transpose_b=transpose_b, name=name)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 759, in apply_op\n    op_def=op_def)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2240, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"C:\\Users\\h_agu\\Desktop\\machine_learning\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1128, in __init__\n    self._traceback = _extract_stack()\n\nInternalError (see above for traceback): Blas SGEMM launch failed : a.shape=(64, 150), b.shape=(150, 100), m=64, n=100, k=150\n\t [[Node: MatMul = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Reshape/_21, HiddenLayer/Variable/read)]]\n\t [[Node: Adam/update_SoftmaxLayer/Variable_1/ApplyAdam/_56 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_325_Adam/update_SoftmaxLayer/Variable_1/ApplyAdam\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#from q2_initialization import xavier_weight_init\n",
    "import data_utils.utilz as du\n",
    "import data_utils.ner as ner\n",
    "from utils import data_iterator\n",
    "from model import LanguageModel\n",
    "\n",
    "class Config(object):\n",
    "  \"\"\"Holds model hyperparams and data information.\n",
    "\n",
    "  The config class is used to store various hyperparameters and dataset\n",
    "  information parameters. Model objects are passed a Config() object at\n",
    "  instantiation.\n",
    "  \"\"\"\n",
    "  embed_size = 50\n",
    "  batch_size = 64\n",
    "  label_size = 5\n",
    "  hidden_size = 100\n",
    "  max_epochs = 24 \n",
    "  #max_epochs = 1\n",
    "  early_stopping = 2\n",
    "  dropout = 0.9\n",
    "  lr = 0.001\n",
    "  l2 = 0.001\n",
    "  window_size = 3\n",
    "\n",
    "class NERModel(LanguageModel):\n",
    "  \"\"\"Implements a NER (Named Entity Recognition) model.\n",
    "\n",
    "  This class implements a deep network for named entity recognition. It\n",
    "  inherits from LanguageModel, which has an add_embedding method in addition to\n",
    "  the standard Model method.\n",
    "  \"\"\"\n",
    "\n",
    "  def load_data(self, debug=False):\n",
    "    \"\"\"Loads starter word-vectors and train/dev/test data.\"\"\"\n",
    "    # Load the starter word vectors\n",
    "    self.wv, word_to_num, num_to_word = ner.load_wv(\n",
    "      'data/ner/vocab.txt', 'data/ner/wordVectors.txt')\n",
    "    tagnames = ['O', 'LOC', 'MISC', 'ORG', 'PER']\n",
    "    self.num_to_tag = dict(enumerate(tagnames))\n",
    "    tag_to_num = {v:k for k,v in self.num_to_tag.items()}\n",
    "\n",
    "    # Load the training set\n",
    "    docs = du.load_dataset('data/ner/train')\n",
    "    self.X_train, self.y_train = du.docs_to_windows(\n",
    "        docs, word_to_num, tag_to_num, wsize=self.config.window_size)\n",
    "    if debug:\n",
    "      self.X_train = self.X_train[:1024]\n",
    "      self.y_train = self.y_train[:1024]\n",
    "\n",
    "    # Load the dev set (for tuning hyperparameters)\n",
    "    docs = du.load_dataset('data/ner/dev')\n",
    "    self.X_dev, self.y_dev = du.docs_to_windows(\n",
    "        docs, word_to_num, tag_to_num, wsize=self.config.window_size)\n",
    "    if debug:\n",
    "      self.X_dev = self.X_dev[:1024]\n",
    "      self.y_dev = self.y_dev[:1024]\n",
    "\n",
    "    # Load the test set (dummy labels only)\n",
    "    docs = du.load_dataset('data/ner/test.masked')\n",
    "    self.X_test, self.y_test = du.docs_to_windows(\n",
    "        docs, word_to_num, tag_to_num, wsize=self.config.window_size)\n",
    "\n",
    "  def add_placeholders(self):\n",
    "    \"\"\"Generate placeholder variables to represent the input tensors\n",
    "\n",
    "    These placeholders are used as inputs by the rest of the model building\n",
    "    code and will be fed data during training.  Note that when \"None\" is in a\n",
    "    placeholder's shape, it's flexible\n",
    "\n",
    "    Adds following nodes to the computational graph\n",
    "\n",
    "    input_placeholder: Input placeholder tensor of shape\n",
    "                       (None, window_size), type tf.int32\n",
    "    labels_placeholder: Labels placeholder tensor of shape\n",
    "                        (None, label_size), type tf.float32\n",
    "    dropout_placeholder: Dropout value placeholder (scalar),\n",
    "                         type tf.float32\n",
    "\n",
    "    Add these placeholders to self as the instance variables\n",
    "  \n",
    "      self.input_placeholder\n",
    "      self.labels_placeholder\n",
    "      self.dropout_placeholder\n",
    "\n",
    "    (Don't change the variable names)\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    self.input_placeholder=tf.placeholder(tf.int32,shape=[None,self.config.window_size],name=\"input_placeholder\")\n",
    "    self.labels_placeholder=tf.placeholder(tf.float32,shape=[None,self.config.label_size],name=\"label_placeholder\")\n",
    "    self.dropout_palceholder=tf.placeholder(tf.float32,name=\"dropout_placeholder\")\n",
    "    ### END YOUR CODE\n",
    "\n",
    "  def create_feed_dict(self, input_batch, dropout, label_batch=None):\n",
    "    \"\"\"Creates the feed_dict for softmax classifier.\n",
    "\n",
    "    A feed_dict takes the form of:\n",
    "\n",
    "    feed_dict = {\n",
    "        <placeholder>: <tensor of values to be passed for placeholder>,\n",
    "        ....\n",
    "    }\n",
    "\n",
    "\n",
    "    Hint: The keys for the feed_dict should be a subset of the placeholder\n",
    "          tensors created in add_placeholders.\n",
    "    Hint: When label_batch is None, don't add a labels entry to the feed_dict.\n",
    "    \n",
    "    Args:\n",
    "      input_batch: A batch of input data.\n",
    "      label_batch: A batch of label data.\n",
    "    Returns:\n",
    "      feed_dict: The feed dictionary mapping from placeholders to values.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    feed_dict = {\n",
    "        self.input_placeholder:input_batch,\n",
    "        self.dropout_palceholder:dropout}\n",
    "    if label_batch is not None:\n",
    "        feed_dict[self.labels_placeholder]=label_batch\n",
    "    ### END YOUR CODE\n",
    "    return feed_dict\n",
    "\n",
    "  def add_embedding(self):\n",
    "    \"\"\"Add embedding layer that maps from vocabulary to vectors.\n",
    "\n",
    "    Creates an embedding tensor (of shape (len(self.wv), embed_size). Use the\n",
    "    input_placeholder to retrieve the embeddings for words in the current batch.\n",
    "\n",
    "    (Words are discrete entities. They need to be transformed into vectors for use\n",
    "    in deep-learning. Although we won't do so in this problem, in practice it's\n",
    "    useful to initialize the embedding with pre-trained word-vectors. For this\n",
    "    problem, using the default initializer is sufficient.)\n",
    "\n",
    "    Hint: This layer should use the input_placeholder to index into the\n",
    "          embedding.\n",
    "    Hint: You might find tf.nn.embedding_lookup useful.\n",
    "    Hint: See following link to understand what -1 in a shape means.\n",
    "      https://www.tensorflow.org/versions/r0.8/api_docs/python/array_ops.html#reshape\n",
    "    Hint: Check the last slide from the TensorFlow lecture.\n",
    "    Hint: Here are the dimensions of the variables you will need to create:\n",
    "\n",
    "      L: (len(self.wv), embed_size)\n",
    "\n",
    "    Returns:\n",
    "      window: tf.Tensor of shape (-1, window_size*embed_size)\n",
    "    \"\"\"\n",
    "    # The embedding lookup is currently only implemented for the CPU\n",
    "    with tf.device('/cpu:0'):\n",
    "      ### YOUR CODE HERE\n",
    "      #raise NotImplementedError\n",
    "      #print(self.config.window_size,self.config.embed_size)\n",
    "      #embedding=tf.Variable(tf.random_uniform(self.wv,maxval=1.0,minval=-1.0))\n",
    "      embedding=tf.Variable(tf.constant(self.wv,dtype=tf.float32))\n",
    "      win=tf.nn.embedding_lookup(embedding,self.input_placeholder)\n",
    "      window=tf.reshape(win,[-1,self.config.window_size*self.config.embed_size])\n",
    "      #print(\"windows:\",len(windows))\n",
    "      ### END YOUR COD\n",
    "      return window\n",
    "\n",
    "  def add_model(self, window):\n",
    "    \"\"\"Adds the 1-hidden-layer NN.\n",
    "\n",
    "    Hint: Use a variable_scope (e.g. \"Layer\") for the first hidden layer, and\n",
    "          another variable_scope (e.g. \"Softmax\") for the linear transformation\n",
    "          preceding the softmax. Make sure to use the xavier_weight_init you\n",
    "          defined in the previous part to initialize weights.\n",
    "    Hint: Make sure to add in regularization and dropout to this network.\n",
    "          Regularization should be an addition to the cost function, while\n",
    "          dropout should be added after both variable scopes.\n",
    "    Hint: You might consider using a tensorflow Graph Collection (e.g\n",
    "          \"total_loss\") to collect the regularization and loss terms (which you\n",
    "          will add in add_loss_op below).\n",
    "    Hint: Here are the dimensions of the various variables you will need to\n",
    "          create\n",
    "\n",
    "          W:  (window_size*embed_size, hidden_size)\n",
    "          b1: (hidden_size,)\n",
    "          U:  (hidden_size, label_size)\n",
    "          b2: (label_size)\n",
    "\n",
    "    https://www.tensorflow.org/versions/r0.7/api_docs/python/framework.html#graph-collections\n",
    "    Args:\n",
    "      window: tf.Tensor of shape (-1, window_size*embed_size)\n",
    "    Returns:\n",
    "      output: tf.Tensor of shape (batch_size, label_size)\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    #tf.InteractiveSession()\n",
    "    config=self.config\n",
    "    xavier_w=xavier_weight_init()\n",
    "    with tf.name_scope(\"HiddenLayer\"):\n",
    "        self.weights=tf.Variable(xavier_w((config.window_size*config.embed_size,config.hidden_size)))\n",
    "        biases1=tf.Variable(xavier_w((config.hidden_size,)))\n",
    "    #print(\"window: \", window.get_shape(), \"wexavier_weight_init()((ghts: \",self.weights.get_shape(), \"biases: \", biases1.get_shape())\n",
    "    h=tf.tanh(tf.matmul(window, self.weights, transpose_b=False) + biases1)\n",
    "    \n",
    "    #print(\"xavier_mat2:\",xavier_mat2,\"xavier_mat1:\",xavier_mat1)\n",
    "    with tf.name_scope(\"SoftmaxLayer\"):\n",
    "        self.u=tf.Variable(xavier_w((config.hidden_size,config.label_size)))\n",
    "        #print(\"blah3\")\n",
    "        biases2=tf.Variable(xavier_w((config.label_size,)))\n",
    "    #print(\"blah4\")\n",
    "    output=tf.matmul(h,self.u,transpose_b=False) + biases2\n",
    "    ### END YOUR CODE\n",
    "    return output \n",
    "\n",
    "  def add_loss_op(self, y):\n",
    "    \"\"\"Adds cross_entropy_loss ops to the computational graph.\n",
    "\n",
    "    Hint: You can use tf.nn.softmax_cross_entropy_with_logits to simplify your\n",
    "          implementation. You might find tf.reduce_mean useful.\n",
    "    Args:\n",
    "      pred: A tensor of shape (batch_size, n_classes)\n",
    "    Returns:\n",
    "      loss: A 0-d tensor (scalar)\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    loss_reg=self.config.l2/2*(tf.reduce_sum(tf.square(self.weights))+ tf.reduce_sum(tf.square(self.u)))\n",
    "    loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y,self.labels_placeholder))+loss_reg\n",
    "    ### END YOUR CODE\n",
    "    return loss\n",
    "\n",
    "  def add_training_op(self, loss):\n",
    "    \"\"\"Sets up the training Ops.\n",
    "\n",
    "    Creates an optimizer and applies the gradients to all trainable variables.\n",
    "    The Op returned by this function is what must be passed to the\n",
    "    `sess.run()` call to cause the model to train. See \n",
    "\n",
    "    https://www.tensorflow.org/versions/r0.7/api_docs/python/train.html#Optimizer\n",
    "\n",
    "    for more information.\n",
    "\n",
    "    Hint: Use tf.train.AdamOptimizer for this model.\n",
    "          Calling optimizer.minimize() will return a train_op object.\n",
    "\n",
    "    Args:\n",
    "      loss: Loss tensor, from cross_entropy_loss.\n",
    "    Returns:\n",
    "      train_op: The Op for training.\n",
    "    \"\"\"\n",
    "    ### YOUR CODE HERE\n",
    "    optimizer=tf.train.AdamOptimizer(self.config.lr)\n",
    "    train_op=optimizer.minimize(loss)\n",
    "    ### END YOUR CODE\n",
    "    return train_op\n",
    "\n",
    "  def __init__(self, config):\n",
    "    \"\"\"Constructs the network using the helper functions defined above.\"\"\"\n",
    "    self.config = config\n",
    "    self.load_data(debug=False)\n",
    "    #self.load_data(debug=True)\n",
    "    self.add_placeholders()\n",
    "    window = self.add_embedding()\n",
    "    y = self.add_model(window)\n",
    "\n",
    "    self.loss = self.add_loss_op(y)\n",
    "    self.predictions = tf.nn.softmax(y)\n",
    "    one_hot_prediction = tf.argmax(self.predictions, 1)\n",
    "    correct_prediction = tf.equal(\n",
    "        tf.argmax(self.labels_placeholder, 1), one_hot_prediction)\n",
    "    self.correct_predictions = tf.reduce_sum(tf.cast(correct_prediction, 'int32'))\n",
    "    self.train_op = self.add_training_op(self.loss)\n",
    "\n",
    "  def run_epoch(self, session, input_data, input_labels,\n",
    "                shuffle=True, verbose=True):\n",
    "    orig_X, orig_y = input_data, input_labels\n",
    "    dp = self.config.dropout\n",
    "    # We're interested in keeping track of the loss and accuracy during training\n",
    "    total_loss = []\n",
    "    total_correct_examples = 0\n",
    "    total_processed_examples = 0\n",
    "    total_steps = len(orig_X) / self.config.batch_size\n",
    "    for step, (x, y) in enumerate(\n",
    "      data_iterator(orig_X, orig_y, batch_size=self.config.batch_size,\n",
    "                   label_size=self.config.label_size, shuffle=shuffle)):\n",
    "        \n",
    "      #print(\"x:\",x.shape,\"y:\",y.shape)\n",
    "    \n",
    "      feed = self.create_feed_dict(input_batch=x, dropout=dp, label_batch=y)\n",
    "      loss, total_correct, _ = session.run(\n",
    "          [self.loss, self.correct_predictions, self.train_op],\n",
    "          feed_dict=feed)\n",
    "      total_processed_examples += len(x)\n",
    "      total_correct_examples += total_correct\n",
    "      total_loss.append(loss)\n",
    "      ##\n",
    "      if verbose and step % verbose == 0:\n",
    "        sys.stdout.write('\\r{} / {} : loss = {}'.format(\n",
    "            step, total_steps, np.mean(total_loss)))\n",
    "        sys.stdout.flush()\n",
    "    if verbose:\n",
    "        sys.stdout.write('\\r')\n",
    "        sys.stdout.flush()\n",
    "    return np.mean(total_loss), total_correct_examples / float(total_processed_examples)\n",
    "\n",
    "  def predict(self, session, X, y=None):\n",
    "    \"\"\"Make predictions from the provided model.\"\"\"\n",
    "    # If y is given, the loss is also calculated\n",
    "    # We deactivate dropout by setting it to 1\n",
    "    dp = 1\n",
    "    losses = []\n",
    "    results = []\n",
    "    if np.any(y):\n",
    "        data = data_iterator(X, y, batch_size=self.config.batch_size,\n",
    "                             label_size=self.config.label_size, shuffle=False)\n",
    "    else:\n",
    "        data = data_iterator(X, batch_size=self.config.batch_size,\n",
    "                             label_size=self.config.label_size, shuffle=False)\n",
    "    for step, (x, y) in enumerate(data):\n",
    "      feed = self.create_feed_dict(input_batch=x, dropout=dp)\n",
    "      if np.any(y):\n",
    "        feed[self.labels_placeholder] = y\n",
    "        loss, preds = session.run(\n",
    "            [self.loss, self.predictions], feed_dict=feed)\n",
    "        losses.append(loss)\n",
    "      else:\n",
    "        preds = session.run(self.predictions, feed_dict=feed)\n",
    "      predicted_indices = preds.argmax(axis=1)\n",
    "      results.extend(predicted_indices)\n",
    "    return np.mean(losses), results\n",
    "\n",
    "def print_confusion(confusion, num_to_tag):\n",
    "    \"\"\"Helper method that prints confusion matrix.\"\"\"\n",
    "    # Summing top to bottom gets the total number of tags guessed as T\n",
    "    total_guessed_tags = confusion.sum(axis=0)\n",
    "    # Summing left to right gets the total number of true tags\n",
    "    total_true_tags = confusion.sum(axis=1)\n",
    "    print()\n",
    "    print(confusion)\n",
    "    for i, tag in sorted(num_to_tag.items()):\n",
    "        prec = confusion[i, i] / float(total_guessed_tags[i])\n",
    "        recall = confusion[i, i] / float(total_true_tags[i])\n",
    "        print('Tag: {} - P {:2.4f} / R {:2.4f}'.format(tag, prec, recall))\n",
    "\n",
    "def calculate_confusion(config, predicted_indices, y_indices):\n",
    "    \"\"\"Helper method that calculates confusion matrix.\"\"\"\n",
    "    confusion = np.zeros((config.label_size, config.label_size), dtype=np.int32)\n",
    "    for i in range(len(y_indices)):\n",
    "        correct_label = y_indices[i]\n",
    "        guessed_label = predicted_indices[i]\n",
    "        confusion[correct_label, guessed_label] += 1\n",
    "    return confusion\n",
    "\n",
    "def save_predictions(predictions, filename):\n",
    "  \"\"\"Saves predictions to provided file.\"\"\"\n",
    "  with open(filename, \"w\") as f:\n",
    "    for prediction in predictions:\n",
    "      f.write(str(prediction) + \"\\n\")\n",
    "\n",
    "def test_NER():\n",
    "  \"\"\"Test NER model implementation.\n",
    "\n",
    "  You can use this function to test your implementation of the Named Entity\n",
    "  Recognition network. When debugging, set max_epochs in the Config object to 1\n",
    "  so you can rapidly iterate.\n",
    "  \"\"\"\n",
    "  config = Config()\n",
    "  with tf.Graph().as_default():\n",
    "    model = NERModel(config)\n",
    "    init = tf.global_variables_initializer()\n",
    "    #init = tf.initialize_all_variables()\n",
    "    saver = tf.train.Saver()\n",
    "    with tf.Session() as session:\n",
    "      best_val_loss = float('inf')\n",
    "      best_val_epoch = 0\n",
    "      session.run(init)\n",
    "      #print(\"blah3\")\n",
    "      for epoch in range(config.max_epochs):\n",
    "        print('Epoch {}'.format(epoch))\n",
    "        start = time.time()\n",
    "        ###\n",
    "        train_loss, train_acc = model.run_epoch(session, model.X_train,\n",
    "                                                model.y_train)\n",
    "        val_loss, predictions = model.predict(session, model.X_dev, model.y_dev)\n",
    "        print('Training loss: {}'.format(train_loss))\n",
    "        print('Training acc: {}'.format(train_acc))\n",
    "        print('Validation loss: {}'.format(val_loss))\n",
    "        if val_loss < best_val_loss:\n",
    "          best_val_loss = val_loss\n",
    "          best_val_epoch = epoch\n",
    "          if not os.path.exists(\"./weights\"):\n",
    "            os.makedirs(\"./weights\")\n",
    "        \n",
    "          saver.save(session, './weights/ner.weights')\n",
    "        if epoch - best_val_epoch > config.early_stopping:\n",
    "          break\n",
    "        ###\n",
    "        confusion = calculate_confusion(config, predictions, model.y_dev)\n",
    "        print_confusion(confusion, model.num_to_tag)\n",
    "        print('Total time: {}'.format(time.time() - start))\n",
    "      \n",
    "      saver.restore(session, './weights/ner.weights')\n",
    "      print('Test')\n",
    "      print('=-=-=')\n",
    "      print('Writing predictions to q2_test.predicted')\n",
    "      _, predictions = model.predict(session, model.X_test, model.y_test)\n",
    "      save_predictions(predictions, \"q2_test.predicted\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  test_NER()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    wv, word_to_num, num_to_word = ner.load_wv(\n",
    "      'data/ner/vocab.txt', 'data/ner/wordVectors.txt')\n",
    "    tagnames = ['O', 'LOC', 'MISC', 'ORG', 'PER']\n",
    "    num_to_tag = dict(enumerate(tagnames))\n",
    "    tag_to_num = {v:k for k,v in num_to_tag.items()}    \n",
    "    docs = du.load_dataset('data/ner/train')\n",
    "    X_train, y_train = du.docs_to_windows(\n",
    "        docs, word_to_num, tag_to_num, wsize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(203621, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-gpu]",
   "language": "python",
   "name": "conda-env-tensorflow-gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
